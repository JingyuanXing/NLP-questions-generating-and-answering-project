# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1somr24ZNtSWCBVItWlX9mQ_Oh9AjjLlf

below are three chunks basic code that helps with basic chunking of nouns
"""

import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize

r = open(file = "set1/set1/a1.txt", mode = "r")
text = r.read()

sent_tokens = sent_tokenize(text)
sents_tagged = [nltk.pos_tag(word_tokenize(sent)) for sent in sent_tokens]
sents_tagged

grammar = r"""
NP: {<DT>?(<JJ>|<JJR>)*(<NN>+|<NNS>|<NNP>+)<IN><DT>?<JJ>*(<NN>+|<NNS>|<NNP>+)} 
    {<DT>?(<JJ>|<JJR>)*(<NN>+|<NNS>|<NNP>+)}
    {<DT>?(<JJ>|<JJR>)*(<NN>|<NNP>|<NNS>)+} 
PP: {<NP><,><NP>+((<,>?<CC>?)<NP>)*}
"""
cp = nltk.RegexpParser(grammar)
result = cp.parse(sents_tagged[1])
print(result)

"""Kristin: \\
Below are the code that's used to generate the list of relations
all_rels contains tuples of (subject class, subject, fill, object class, object) \\
For example ('PERSON', 'Sneferu', 'was succeeded by his $ son ,  ,', 'GPE', 'Khufu') \\\
TODO:
- We can easily implement the question based on suitable syntax. For example, PERSON -> WHO, "WHO" + fill + object -> Who was succeeded by his son Khufu? 
- there are some mislabeling in the tag. Like, Khufu is a person instead of a location.
- Some of the relations generated are useless, need to do some manual check, or do some twist and turn when generating questions.
"""

import os, nltk, re, pprint
from nltk.sem import relextract
from nltk.corpus import state_union
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk import ne_chunk, pos_tag


f = open('Development_data/set1/a1.txt')
raw = f.read()

sents = sent_tokenize(raw)

words = word_tokenize(raw)
pos_words = nltk.pos_tag(words)
ne_words = ne_chunk(pos_words)
# print(words)
# print(ne_words)
# ne_words.draw()


pairs = relextract.tree2semi_rel(ne_words)
reldicts = relextract.semi_rel2reldict(pairs)

for r in reldicts[0:10]:
    print('=' * 20)
    print(r['subjtext'])
    print(r['filler'])
    print(r['objtext'])



# helper function
def cut (s):
	return s.split("/", 1)[0]

all_rels = []

# post-process
# truncate the POS tag, and form each of them into string
# also check that if filler contains the end of sentence. 
# if so, ignore this relation
for rel in reldicts:
	subjects = map(cut, word_tokenize(rel['subjtext']))
	fillers = map(cut, word_tokenize(rel['filler']))
	objects = map(cut, word_tokenize(rel['objtext']))
	sub = " ".join(subjects)
	fil = " ".join(fillers)
	obj = " ".join(objects)
	if (len(sent_tokenize(fil)) == 1):
		all_rels.append((rel['subjclass'], 
			sub, 
			fil, 
			rel['objclass'],
			obj))

for r in all_rels:
	print(r)